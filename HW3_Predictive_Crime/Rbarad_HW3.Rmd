---
title: 'Home Work 3 Predictive Policing'
author: "Richard"
date: "10/23/2023"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(tidyverse)
library(sf)
library(tidycensus)
library(viridis)
library(gridExtra)
library(FNN) #This is needed for KNN Function
library(spdep) #This is for the Local Morans I calcuations
library(kableExtra)
library(spatstat.explore)
library(classInt)   # for KDE and ML risk class intervals

# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```

## Read in Data from DC

This uses the Socrata package for some data sets.

Note where we bring in burglary data - you will want to vary this part to do your homework!

```{r read_theft_data, warning=False, message=False}
thefts2021<- 
  st_read("https://maps2.dcgis.dc.gov/dcgis/rest/services/FEEDS/MPD/MapServer/3/query?outFields=*&where=1%3D1&f=geojson") %>%
  st_transform('ESRI:103376') %>%
  filter(OFFENSE == 'THEFT/OTHER')

dc_quadrents<- st_read('https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/Administrative_Other_Boundaries_WebMercator/MapServer/11/query?outFields=*&where=1%3D1&f=geojson') %>%
  st_transform('ESRI:103376')

dc_water <- st_read('https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/Planimetrics_2015/MapServer/14/query?outFields=*&where=1%3D1&f=geojson') %>%
  st_transform('ESRI:103376') %>%
  dplyr::filter(CAPTUREACTION == 'A')


```

## visualizing point data

Plotting point data and density

> How do we analyze point data?

> Are there other geometries useful to represent point locations?

```{r make_maps, fig.width=6, fig.height=4}
# uses grid.arrange to organize independent plots
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = dc_quadrents, fill = "white",color='transparent') +
  geom_sf(data=dc_water,fill='lightblue',color='transparent')+
  geom_sf(data = thefts2021, colour="orange", size=0.1, show.legend = "point") +
  labs(title= "Thefts (Non Auto), Washington DC, 2023") +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10') +
  mapTheme(title_size = 14),

ggplot() + 
  geom_sf(data = dc_quadrents, fill = "white",color='transparent') +
  stat_density2d(data = data.frame(st_coordinates(thefts2021)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 100, geom = 'polygon') +
  scale_fill_gradient(low = "yellow", high = "red")+
  scale_alpha(range = c(0.00, 0.95), guide = FALSE) +
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  labs(title = "Density of Non Auto Thefts") +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10') +
  mapTheme(title_size = 14) + theme(legend.position = "none")
)
```

## Creating a fishnet grid

```{r, make_fishnet}

fishnet <- 
  st_make_grid(dc_quadrents,
               cellsize = 5280/4, 
               square = TRUE) %>%
  .[dc_quadrents] %>%            # fast way to select intersecting polygons
  st_sf() %>%
  mutate(uniqueID = 1:n()) %>%
  st_transform('ESRI:103376')
```

### Aggregate points to the fishnet

```{r, fishnet}
## add a value of 1 to each crime, sum them with aggregate

theft_net <- st_join(thefts2021,fishnet) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>% tally() %>%
  rename(theft_count = n) %>%
  left_join(fishnet,.,by = "uniqueID") %>%
  mutate(theft_count = ifelse(is.na(theft_count),0,theft_count),
         cvID = sample(round(nrow(fishnet) / 24), size=nrow(fishnet), replace = TRUE))

ggplot()+
  geom_sf(data = theft_net, aes(fill=theft_count), color='transparent')+
  scale_fill_viridis(option="rocket",direction=-1)+
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10') +
  mapTheme()


# For demo. requires updated mapview package
# xx <- mapview::mapview(crime_net, zcol = "countBurglaries")
# yy <- mapview::mapview(mutate(burglaries, ID = seq(1:n())))
# xx + yy
```


## Modeling Spatial Features

> What features would be helpful in predicting the location of burglaries?
>
> What might these features be problematic?
>
> hint: for all the reasons we learned in class

```{r}
## only pulling a single variable for our model to keep it simple

illegaldumping <- st_read('https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/ServiceRequests/MapServer/12/query?where=SERVICECODEDESCRIPTION%3D%27Illegal+Dumping%27&f=geojson') %>%
  st_transform('ESRI:103376')

rodents <- st_read('https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/ServiceRequests/MapServer/12/query?where=SERVICECODEDESCRIPTION%3D%27Rodent+Inspection+and+Treatment%27&f=geojson') %>%
  st_transform('ESRI:103376')

net1 <- illegaldumping %>%
  st_join(fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(count = n()) %>%
  rename(illegaldumping_count = count) %>%
  left_join(theft_net, ., by = "uniqueID") %>%
  mutate(illegaldumping_count = ifelse(is.na(illegaldumping_count),0,illegaldumping_count))

net1 <- rodents %>%
  st_join(fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(count = n()) %>%
  rename(rodent_count = count) %>%
  left_join(net1, ., by = "uniqueID") %>%
  mutate(rodent_count = ifelse(is.na(rodent_count),0,rodent_count))

restaurants <- st_read('https://services.arcgis.com/EDxZDh4HqQ1a9KvA/arcgis/rest/services/cgabris_blueraster_Washington_DC_Layers/FeatureServer/8/query?where=1=1&f=geojson') %>%
  st_transform('ESRI:103376')

net1 <- restaurants %>%
  st_join(fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID) %>%
  summarize(count = n()) %>%
  rename(restaurants_count = count) %>%
  left_join(net1, ., by = "uniqueID") %>%
  mutate(restaurants_count = ifelse(is.na(restaurants_count),0,restaurants_count))

```

## Modeling Spatial Features

```{r tidycensus}

variables =c('B06010_001E', #Total
             'B06010_002E', #Total With No Income
            'B06010_004E', #Estimate!!Total:!!With income:!!$1 to $9,999 or loss
            'B06010_005E', #Estimate!!Total:!!With income:!!$10,000 to $14,999
            'B06010_006E', #Estimate!!Total:!!With income:!!$15,000 to $24,999
            'B06010_007E', #Estimate!!Total:!!With income:!!$25,000 to $34,999
            'B06010_011E') #Estimate!!Total:!!With income:!!$75,000 or more

dccensus_data <-
  get_acs('tract',
          variables = variables,
          year = 2021,
          state = 'DC',
          geometry = TRUE,
          output = 'wide'
          ) %>%
dplyr::select(-ends_with('M')) %>%
  dplyr::filter(B06010_001E > 1000) %>%
  mutate(percent_poor = (B06010_004E + B06010_005E + B06010_006E)/B06010_001E,
         percent_BO = (B06010_011E / B06010_001E),
         wealth_inequality_index = (percent_poor * percent_BO * 4)) %>%
  st_transform('ESRI:103376')

net1 <- st_join(st_centroid(fishnet), dccensus_data %>% dplyr::select(wealth_inequality_index)) %>%
  st_drop_geometry() %>%
  left_join(net1,.,by="uniqueID") %>%
  drop_na()
```

# Nearest Neighbor Feature

```{r}
# convinience to reduce length of function names.
st_c    <- st_coordinates
st_coid <- st_centroid

## create NN from abandoned cars
net1 <- net1 %>%
    mutate(restaurants.nn = nn_function(st_c(st_coid(net1)), 
                                           st_c(restaurants),
                                           k = 3),
           rodents.nn = nn_function(st_c(st_coid(net1)), 
                                           st_c(rodents),
                                           k = 10),
          illegaldumping.nn = nn_function(st_c(st_coid(net1)), 
                                           st_c(illegaldumping),
                                           k = 10)
           )
```

# Filter out grid squares in water

```{r}

centroid <- st_centroid(net1)

net1 <- centroid[st_disjoint(centroid,st_union(dc_water)) %>% lengths > 0, ] %>%
  st_drop_geometry() %>%
  left_join(.,net1) %>%
  st_sf() 

```


```{r make_maps, fig.width=12, fig.height=8}
## Visualize the Risk Factors

grid.arrange(ncol=3,nrow=3,
ggplot()+
  geom_sf(data=net1,aes(fill=illegaldumping_count),color='transparent')+
  scale_fill_viridis(option="rocket",direction=-1)+
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10')+
  mapTheme(),
ggplot()+
  geom_sf(data=net1,aes(fill=restaurants_count),color='transparent')+
  scale_fill_viridis(option="rocket",direction=-1)+
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10')+
  mapTheme(),
ggplot()+
  geom_sf(data=net1,aes(fill=restaurants.nn),color='transparent')+
  scale_fill_viridis(option="rocket",direction=-1)+
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10')+
  mapTheme(),
ggplot()+
  geom_sf(data=net1,aes(fill=wealth_inequality_index),color='transparent')+
  scale_fill_viridis(option="rocket",direction=-1)+
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10')+
  mapTheme(),
ggplot()+
  geom_sf(data=net1,aes(fill=rodent_count),color='transparent')+
  scale_fill_viridis(option="rocket",direction=-1)+
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10')+
  mapTheme(),
ggplot()+
  geom_sf(data=net1,aes(fill=rodents.nn),color='transparent')+
  scale_fill_viridis(option="rocket",direction=-1)+
  geom_sf(data=dc_water,fill='lightblue',color='transparent') +
  geom_sf(data = dc_quadrents, fill='transparent',color='grey10')+
  mapTheme()
)

```

### Join in areal data

Using spatial joins to join *centroids* of fishnets to polygon for neighborhoods and districts.

> What issues arise when we try to join polygons to polygons in space?

```{r join_police_districts_wards}

police_districts <- st_read('https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/Public_Safety_WebMercator/MapServer/9/query?outFields=*&where=1%3D1&f=geojson') %>%
  st_transform('ESRI:103376') %>%
  rename(police_name = NAME)

neighboorhood <- st_read('https://maps2.dcgis.dc.gov/dcgis/rest/services/DCGIS_DATA/Administrative_Other_Boundaries_WebMercator/MapServer/17/query?outFields=*&where=1%3D1&f=geojson') %>%
  st_transform('ESRI:103376') %>%
  rename(nbh_names = NBH_NAMES)

final_net <-
  st_centroid(fishnet) %>%
    st_join(dplyr::select(neighboorhood, nbh_names)) %>%
    st_join(dplyr::select(police_districts, police_name)) %>%
      st_drop_geometry() %>%
      left_join(net1,.,by='uniqueID') %>%
  na.omit()

```

## Local Moran's I for fishnet grid cells

We use the {spdep} package to to build neighborhood weights and list to calculate local Moran's I.

```{r}
## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)

# print(final_net.weights, zero.policy=TRUE)
```

```{r}
## see ?localmoran
local_morans <- localmoran(final_net$theft_count, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(Theft_count = theft_count, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.01, 1, 0)) %>%
  gather(Variable, Value, -geometry)
  
```

### Plotting local Moran's I results

This is a complex code chunk - it's a loop which builds ggplots of local Moran's for each of your `vars`

> What does a significant hot spot tell us about the distribution of burglaries?

```{r}
## This is just for plotting
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 10) + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Theft"))
```
## Correlation Plots

```{r, correlation_plot, fig.height=9,fig.width=7}

correlation.long <-
  st_drop_geometry(final_net) %>%
    dplyr::select(-uniqueID, -cvID, -police_name, -nbh_names) %>%
    gather(Variable, Value, -theft_count)

correlation.cor <-
  correlation.long %>%
    group_by(Variable) %>%
    summarize(correlation = cor(Value, theft_count, use = "complete.obs"))
    
ggplot(correlation.long, aes(Value, theft_count)) +
  geom_point(size = 0.1) +
  geom_text(data = correlation.cor, aes(label = paste("r =", round(correlation, 2))),
            x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  facet_wrap(~Variable, ncol = 2, scales = "free") +
  labs(title = "Theft count as a function of risk factors") +
  plotTheme()
```

```{r, dependant_variable_hist, fig.height}

ggplot()+
  geom_histogram(data=final_net,aes(x=theft_count),fill='grey60',color='black',bins=100)+
  plotTheme()

```


```{r crossvalidation, results='hide'}

# View(crossValidate)

## define the variables we want
reg.vars <- c("illegaldumping.nn", "restaurants.nn","rodents.nn","wealth_inequality_index")

## RUN REGRESSIONS
reg.spatialCV <- crossValidate(
  dataset = final_net,
  id = "nbh_names",                           
  dependentVariable = "theft_count",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = nbh_names, theft_count, Prediction, geometry)

reg.CV <- crossValidate(
  dataset = final_net,
  id = "cvID",                           
  dependentVariable = "theft_count",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, theft_count, Prediction, geometry)

reg.summary <- 
  rbind(mutate(reg.spatialCV,Error = Prediction - theft_count,
               Regression = "Spatial Location CV"),
        mutate(reg.CV, Error = Prediction - theft_count,
               Regression = "Random k-fold CV"))
```

### Calculating Errors across space

```{r}
error_by_reg_and_fold <- 
  reg.summary %>%
    group_by(Regression, cvID) %>% 
    summarize(Mean_Error = mean(Prediction - theft_count, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  ggplot() +
    geom_sf(aes(fill = MAE)) +
    facet_wrap(~Regression) +
    scale_fill_viridis() +
    labs(title = "Theft errors by Regression") +
    mapTheme() + theme(legend.position="bottom")
```


``` {r}
st_drop_geometry(reg.summary) %>%
  group_by(Regression) %>% 
  mutate(abs_error = abs(Error)) %>%
    summarize(Mean_MAE = round(mean(abs(abs_error)), 2),
              SD_MAE = round(sd(abs(abs_error), 2))) %>%
  kable() %>%
  kable_classic()
```

## Racial Analysis

``` {r}
tracts20 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E"), 
          year = 2020, state='DC', geometry=T) %>%
  st_transform('ESRI:103376')  %>% 
  dplyr::select(variable, estimate, GEOID) %>%
  spread(variable, estimate) %>%
  rename(TotalPop = B01001_001,
         NumberWhites = B01001A_001) %>%
  mutate(percentWhite = NumberWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority_White", "Majority_Non_White"))

ggplot()+
  geom_sf(data=tracts20, aes(fill=raceContext))
```

``` {r}
reg.summary %>% 
    st_centroid() %>%
    st_join(tracts20) %>%
    na.omit() %>%
      st_drop_geometry() %>%
      group_by(Regression, raceContext) %>%
      summarize(mean.Error = mean(Error, na.rm = T)) %>%
      spread(raceContext, mean.Error) %>%
      kable(caption = "Mean Error by neighborhood racial context") %>%
        kable_styling("striped", full_width = F)  
```


## Density vs predictions

The `spatstat.explore` package's `density.ppp` function gets us kernel density estimates with varying search radii. We can use these to compare accuracy with our predictions - we can join them to our `final_net` and them compare estimates.

Note that the code here is *different* than in the book - it has been updated to keep up with changes in packages.

```{r read_theft_data, warning=False, message=False}
thefts2022<- 
  st_read("https://maps2.dcgis.dc.gov/dcgis/rest/services/FEEDS/MPD/MapServer/4/query?outFields=*&where=1%3D1&f=geojson") %>%
  st_transform('ESRI:103376') %>%
  filter(OFFENSE == 'THEFT/OTHER')
```

```{r kernel_density}
theft_ppp <- as.ppp(st_coordinates(thefts2021), W = st_bbox(final_net))
theft.1000 <- spatstat.explore::density.ppp(theft_ppp, 1000)

theft_KDE_sum <- as.data.frame(theft.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) 
kde_breaks <- classIntervals(theft_KDE_sum$value, 
                             n = 5, "fisher")
theft_KDE_sf <- theft_KDE_sum %>%
  mutate(label = "Kernel Density",
         Risk_Category = classInt::findCols(kde_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(thefts2022) %>% mutate(theftcount = 1), ., sum) %>%
    mutate(theftcount = replace_na(theftcount, 0))) %>%
  dplyr::select(label, Risk_Category, theftcount)
```

```{r}
ml_breaks <- classIntervals(reg.spatialCV$Prediction, 
                             n = 5, "fisher")
theft_risk_sf <-
  reg.spatialCV %>%
  mutate(label = "Risk Predictions",
         Risk_Category =classInt::findCols(ml_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(thefts2022) %>% mutate(theftcount = 1), ., sum) %>%
      mutate(theftcount = replace_na(theftcount, 0))) %>%
  dplyr::select(label,Risk_Category, theftcount)
```

```{r}
rbind(theft_KDE_sf, theft_risk_sf) %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = thefts2022, size = .1, colour = "grey50") +
    facet_wrap(~label, ) +
    scale_fill_viridis_d(option="rocket",direction=-1) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2021 theft risk predictions; 2022 burglaries") +
    mapTheme(title_size = 14)
```


```{r}
rbind(theft_KDE_sf, theft_risk_sf) %>%
  st_drop_geometry() %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(theftcount = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Pcnt_of_test_set_crimes = theftcount / sum(theftcount)) %>%
    ggplot(aes(Risk_Category,Pcnt_of_test_set_crimes)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_viridis(discrete = TRUE, name = "Model") +
      labs(title = "Risk prediction vs. Kernel density, 2022 theft",
           y = "% of  Test Set Thefts Per Model (per model)",
           x = "Risk Category") +
  theme_bw() +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
```
